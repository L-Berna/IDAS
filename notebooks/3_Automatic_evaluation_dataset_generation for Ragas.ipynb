{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9e012de",
   "metadata": {},
   "source": [
    "# 3. Automatic Evaluation Dataset Generation for Ragas\n",
    "\n",
    "In this notebook, we generate an automatic or synthetic evaluation dataset that we can use to evaluate our RAG pipeline using Ragas. Ragas is a framework that helps you evaluate your Retrieval Augmented Generation (RAG) pipelines.  \n",
    "\n",
    "Authors:\n",
    "- Luis Bernardo Hernandez Salinas\n",
    "- Juan R. Terven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dab5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a63f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model to use\n",
    "llm_name = \"gpt-4o\"\n",
    "\n",
    "# API key \n",
    "client = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "print(f\"Using model {llm_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77034e3",
   "metadata": {},
   "source": [
    "## Get the documents splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b10cdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader('chevrolet-spark.pdf')\n",
    "\n",
    "# load pdf pages\n",
    "pages = loader.load()\n",
    "print(f\"The document has {len(pages)} pages\")\n",
    "\n",
    "# RecursiveCharacterTextSplitter with overlap\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 2000,  # chunk size in characters\n",
    "    chunk_overlap = 150 # Caracteres de solapamiento entre segmentos consecutivos.\n",
    ")\n",
    "\n",
    "# split documents\n",
    "splits = text_splitter.split_documents(pages)\n",
    "\n",
    "print(f\"Generated {len(splits)} splits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5238f437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first split with info\n",
    "first_split = 46\n",
    "# last split with info\n",
    "last_split = 200\n",
    "\n",
    "splits[46]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51decc60",
   "metadata": {},
   "source": [
    "## Generating a synthetic question for testing the question generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91311f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResponseSchema is a class that acts as the architectural blueprint for data elements in a response.\n",
    "# Imagine it as the template for each piece in a complex puzzle of structured output.\n",
    "question_schema = ResponseSchema(\n",
    "    name='question',\n",
    "    description='a question about the context.'\n",
    ")\n",
    "question_response_schemas = [question_schema]\n",
    "\n",
    "# StructuredOutputParser is a class crafted for decoding and processing structured outputs,\n",
    "# like a detective unraveling the mysteries of data (think JSON) returned from a source (often a language model)\n",
    "question_output_parser = StructuredOutputParser.from_response_schemas(question_response_schemas)\n",
    "format_instructions = question_output_parser.get_format_instructions()\n",
    "\n",
    "# Define a template for the question generator\n",
    "qa_templates = \"\"\"\\\n",
    "You are a car expert creating a test for car users. For each context, create a question that is specific to the context.\n",
    "Avoid creating generic or general questions. All the questions must be in english.\n",
    "\n",
    "question: a question about the context.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "question\n",
    "\n",
    "context: {context}\n",
    "\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_template(template=qa_templates)\n",
    "\n",
    "# Generate a question from the provided context\n",
    "messages = prompt_template.format_messages(\n",
    "    context=splits[50],\n",
    "    format_instructions=format_instructions\n",
    ")\n",
    "response = llm(messages) # Utiliza el modelo de lenguaje para generar respuestas.\n",
    "output_dict = question_output_parser.parse(response.content) # Procesa y extrae información estructurada de la respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed1615c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for k, v in output_dict.items():\n",
    "    print(k)  # Imprime la clave del par actual.\n",
    "    print(\"\")\n",
    "    print(v)  # Imprime el valor asociado a la clave actual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cbc5bb",
   "metadata": {},
   "source": [
    "## Generate 20 synthetic questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab34d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialización de la lista para almacenar los triples de pregunta, respuesta y contexto.\n",
    "qac_triples = []\n",
    "\n",
    "# Procesamiento de los primeros 20 segmentos de texto con una barra de progreso visible.\n",
    "for text in tqdm(random.sample(splits[first_split:last_split], 20)):\n",
    "    # Formateo de mensajes basados en el contexto para enviar al modelo de lenguaje.\n",
    "    messages = prompt_template.format_messages(\n",
    "        context=text,\n",
    "        format_instructions=format_instructions\n",
    "    )\n",
    "    \n",
    "    # Generación de respuesta mediante el modelo de lenguaje.\n",
    "    response = llm(messages)\n",
    "    \n",
    "    try:\n",
    "        # Intento de parsear la respuesta para extraer datos estructurados.\n",
    "        output_dict = question_output_parser.parse(response.content)\n",
    "    except Exception as e:\n",
    "        # Continuar con el siguiente segmento de texto si hay un error en el parseo.\n",
    "        continue\n",
    "    \n",
    "    # Añadir el texto original como contexto en el diccionario de salida.\n",
    "    output_dict['context'] = text\n",
    "    # Añadir el diccionario actualizado a la lista de triples.\n",
    "    qac_triples.append(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6392b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "qac_triples[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321c3732",
   "metadata": {},
   "source": [
    "## Insert the answer to each question "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2957bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_generation_llm = ChatOpenAI(model=llm_name, temperature=0)\n",
    "answer_schema = ResponseSchema(\n",
    "    name=\"answer\",\n",
    "    description=\"an answer to the question\"\n",
    ")\n",
    "answer_response_schemas = [\n",
    "    answer_schema,\n",
    "]\n",
    "\n",
    "answer_output_parser = StructuredOutputParser.from_response_schemas(answer_response_schemas)\n",
    "format_instructions = answer_output_parser.get_format_instructions()\n",
    "\n",
    "qa_template = \"\"\"\\\n",
    "You are a car expert creating a test for car users. For each question and context, create an answer.\n",
    "answer: an answer about the context.\n",
    "Format the output as JSON with the following keys:\n",
    "answer\n",
    "question: {question}\n",
    "context: {context}\n",
    "\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_template(template=qa_template)\n",
    "answer_generation_chain = answer_generation_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcef1d2b",
   "metadata": {},
   "source": [
    "### Let's first try with a single one and check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484229fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = prompt_template.format_messages(\n",
    "    context=qac_triples[0][\"context\"],\n",
    "    question=qac_triples[0][\"question\"],\n",
    "    format_instructions=format_instructions\n",
    ")\n",
    "response = answer_generation_chain.invoke(messages)\n",
    "output_dict = answer_output_parser.parse(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016aa947",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in output_dict.items():\n",
    "    print(k)\n",
    "    print(\"-----\")\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c524c3ed",
   "metadata": {},
   "source": [
    "### Now get the answers on all the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a55607",
   "metadata": {},
   "outputs": [],
   "source": [
    "for triple in tqdm(qac_triples):\n",
    "    messages = prompt_template.format_messages(\n",
    "        context=triple['context'],\n",
    "        question=triple['question'],\n",
    "        format_instructions=format_instructions\n",
    "    )\n",
    "    response = answer_generation_chain.invoke(messages)\n",
    "    \n",
    "    try:\n",
    "        output_dict = answer_output_parser.parse(response.content)\n",
    "    except Exception as e:\n",
    "        continue\n",
    "    \n",
    "    # Actualización del triple actual con la respuesta generada.\n",
    "    triple['answer'] = output_dict['answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdbea6b",
   "metadata": {},
   "source": [
    "## Combine questions, contexts, and answers for evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d13b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To pandas\n",
    "ground_truth_qac_set = pd.DataFrame(qac_triples)\n",
    "\n",
    "# Make sure context is string\n",
    "ground_truth_qac_set[\"context\"] = ground_truth_qac_set[\"context\"].map(lambda x: str(x.page_content))\n",
    "\n",
    "# rename answer to groundtruth\n",
    "ground_truth_qac_set = ground_truth_qac_set.rename(columns={\"answer\" : \"ground_truth\"})\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "eval_dataset = Dataset.from_pandas(ground_truth_qac_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d7d0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29204c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70db560",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset.to_csv('ground_truth_qac_set_spark_2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idas",
   "language": "python",
   "name": "idas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
